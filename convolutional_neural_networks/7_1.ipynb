{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume that the size of the convolution kernel is $\\triangle = 0$. Show that in this case the convolution kernel implements an MLP independently for each set of channels. This leads to the Network in Network architectures (Lin et al., 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "[\\mathsf{H}]_{i,j,d} =& \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c} \\\\\n",
    "=& \\sum_c [\\mathsf{V}]_{c, d} [\\mathsf{X}]_{i, j, c}\n",
    "\\end{align}$$ \n",
    "\n",
    "$$[\\mathsf{H}]_{k,d} = \\sum_c [\\mathsf{V}]_{c, d} [\\mathsf{X}]_{k, c}$$ \n",
    "\n",
    "It is equal to MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio data is often represented as a one-dimensional sequence. \n",
    "    1. When might you want to impose locality and translation invariance for audio? \n",
    "    1. Derive the convolution operations for audio.\n",
    "    1. Can you treat audio using the same tools as computer vision? Hint: use the spectrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) capturing short-term audio events or locally relevant features, such as phonemes and syllables\n",
    "\n",
    "(2) The audio data X is a one dimension vector.\n",
    "\n",
    "$$[\\mathsf{H}]_{k,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, c, d} [\\mathsf{X}]_{k+a, c}$$ \n",
    "\n",
    "(3) A spectrogram is a visual representation of the spectrum of frequencies in a signal as they vary with time. Itâ€™s akin to an image where the x-axis represents time, the y-axis represents frequency, and the color/intensity represents the amplitude or energy. Then we can apply convolution operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Why might translation invariance not be a good idea after all? Give an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In audio understanding, the timing and temporal relationships between signals are crucial for distinguish the meaning of it. Applying translation invariance to audio data could lead to the loss of the sequence information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Do you think that convolutional layers might also be applicable for text data? Which problems might you encounter with language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is applicable for text data. But the text lacks this inherent spatial arrangement and the translation invariance is not a good assumption. Sentences or documents can have varying lengths, making it challenging to directly apply standard convolutional operations. CNNs inherently lack the ability to model the absolute positions of words in a sentence, which can be important for understanding language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What happens with convolutions when an object is at the boundary of an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutions cannot be implemented at the boundary because $[X]_{i+a,j+b,c}$ is out of the image range. There are two solutions:\n",
    "\n",
    "(1) no padding: the filter is only applied to positions where it fully overlaps with the image. In this way, it might lost the information at the boundary.\n",
    "\n",
    "(2) Padding: adding padding to the input image so that the output feature map has the same spatial dimensions as the input. The missing values are often treated as zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Prove that the convolution is symmetric, i.e., $f * g = g * f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(f * g)(\\mathbf{x}) = \\int_{-\\infty}^{\\infty} f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n",
    "\n",
    "let $\\mathbf{x}-\\mathbf{z}=\\mathbf{y}$:\n",
    "\n",
    "$$\\begin{align}\n",
    "(g * f)(\\mathbf{x}) &= \\int_{-\\infty}^{\\infty} g(\\mathbf{z}) f(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}\n",
    "&= \\int_{\\infty}^{-\\infty} f(\\mathbf{y}) g(\\mathbf{x-y}) d\\mathbf{(-y)}\n",
    "&=(f * g)(\\mathbf{x})\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
