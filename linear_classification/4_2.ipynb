{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.use_svg_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST(d2l.DataModule):  #@save\n",
    "    \"\"\"The Fashion-MNIST dataset.\"\"\"\n",
    "    def __init__(self, batch_size=64, resize=(28, 28)):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        trans = transforms.Compose([transforms.Resize(resize),\n",
    "                                    transforms.ToTensor()])\n",
    "        self.train = torchvision.datasets.FashionMNIST(\n",
    "            root=self.root, train=True, transform=trans, download=True)\n",
    "        self.val = torchvision.datasets.FashionMNIST(\n",
    "            root=self.root, train=False, transform=trans, download=True)\n",
    "    \n",
    "    def text_labels(self, indices):\n",
    "        \"\"\"Return text labels.\"\"\"\n",
    "        labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "        return [labels[int(i)] for i in indices]\n",
    "    \n",
    "    def get_dataloader(self, train):\n",
    "        data = self.train if train else self.val\n",
    "        return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train,\n",
    "                                        num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = FashionMNIST(resize=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_time(data):\n",
    "    tic = time.time()\n",
    "    for X, y in data.train_dataloader():\n",
    "        continue\n",
    "    return time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Does reducing the batch_size (for instance, to 1) affect the reading performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.73 sec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{load_time(FashionMNIST(batch_size=64, resize=(32, 32))):.2f} sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'47.61 sec'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{load_time(FashionMNIST(batch_size=1, resize=(32, 32))):.2f} sec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the batch size is reduced, the number of examples processed together in each iteration decreases. This can lead to an increase in the frequency of data loading and preprocessing operations, which may increase the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The data iterator performance is important. Do you think the current implementation is fast enough? Explore various options to improve it. Use a system profiler to find out where the bottlenecks are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         191638 function calls (191632 primitive calls) in 10.267 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      676    8.578    0.013    8.578    0.013 {built-in method _winapi.WaitForMultipleObjects}\n",
      "       10    0.736    0.074    0.736    0.074 {built-in method _winapi.WaitForSingleObject}\n",
      "      962    0.173    0.000    0.173    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        4    0.086    0.022    0.086    0.022 {built-in method _winapi.CreateProcess}\n",
      "        1    0.070    0.070   10.267   10.267 2419004203.py:1(load_time)\n",
      "     1876    0.070    0.000    0.070    0.000 {built-in method _new_shared_filename_cpu}\n",
      "      938    0.042    0.000    0.250    0.000 {built-in method _pickle.loads}\n",
      "     1876    0.039    0.000    0.039    0.000 {built-in method torch.tensor}\n",
      "     1876    0.031    0.000    0.031    0.000 {built-in method _winapi.PeekNamedPipe}\n",
      "      939    0.029    0.000    0.029    0.000 {built-in method torch._ops.profiler.}\n",
      "        8    0.029    0.004    0.029    0.004 {method '_share_filename_cpu_' of 'torch._C.StorageBase' objects}\n",
      "      939    0.025    0.000    0.025    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "     1876    0.023    0.000    0.023    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
      "      940    0.022    0.000    0.048    0.000 sampler.py:241(__iter__)\n",
      "     2559    0.019    0.000    0.019    0.000 {built-in method _winapi.ReadFile}\n",
      "      683    0.016    0.000    8.625    0.013 connection.py:827(wait)\n",
      "      939    0.012    0.000    9.883    0.011 dataloader.py:629(__next__)\n",
      "        2    0.011    0.006    0.011    0.006 {built-in method torch.randperm}\n",
      "      938    0.011    0.000    8.972    0.010 queues.py:98(get)\n",
      "      939    0.011    0.000    9.793    0.010 dataloader.py:1299(_next_data)\n",
      "     1876    0.010    0.000    0.112    0.000 reductions.py:319(rebuild_storage_filename)\n",
      "      939    0.010    0.000    0.042    0.000 profiler.py:495(__exit__)\n",
      "    60001    0.009    0.000    0.026    0.000 sampler.py:117(__iter__)\n",
      "      676    0.009    0.000    0.009    0.000 {method 'cancel' of '_winapi.Overlapped' objects}\n",
      "     1876    0.008    0.000    0.020    0.000 reductions.py:339(rebuild_typed_storage)\n",
      "     1876    0.008    0.000    0.076    0.000 reductions.py:98(rebuild_tensor)\n",
      "      938    0.008    0.000    8.650    0.009 connection.py:326(_poll)\n",
      "      938    0.007    0.000    0.045    0.000 connection.py:294(_recv_bytes)\n",
      "      946    0.007    0.000    0.253    0.000 dataloader.py:1348(_try_put_index)\n",
      "      942    0.007    0.000    0.196    0.000 queues.py:86(put)\n",
      "      683    0.007    0.000    8.586    0.013 connection.py:805(_exhaustive_wait)\n",
      "     1884    0.007    0.000    0.016    0.000 reductions.py:69(__setitem__)\n",
      "      938    0.007    0.000    0.029    0.000 connection.py:332(_get_more_data)\n",
      "     1888    0.006    0.000    0.006    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "     1876    0.006    0.000    0.068    0.000 _utils.py:145(_rebuild_tensor)\n",
      "        2    0.005    0.003    0.005    0.003 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "      938    0.005    0.000    0.052    0.000 connection.py:208(recv_bytes)\n",
      "     1876    0.005    0.000    0.007    0.000 reductions.py:65(get)\n",
      "     1884    0.005    0.000    0.006    0.000 reductions.py:28(__init__)\n",
      "     1884    0.005    0.000    0.006    0.000 storage.py:404(__init__)\n",
      "     1884    0.005    0.000    0.005    0.000 storage.py:332(__new__)\n",
      "      939    0.004    0.000    0.006    0.000 profiler.py:482(__init__)\n",
      "      939    0.004    0.000    0.030    0.000 profiler.py:491(__enter__)\n",
      "     2564    0.003    0.000    0.003    0.000 {method 'GetOverlappedResult' of '_winapi.Overlapped' objects}\n",
      "      946    0.003    0.000    0.008    0.000 threading.py:351(notify)\n",
      "      945    0.003    0.000    0.003    0.000 {method 'release' of '_thread.lock' objects}\n",
      "     1881    0.003    0.000    0.003    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "      938    0.003    0.000    8.975    0.010 dataloader.py:1120(_try_get_data)\n",
      "       16    0.003    0.000    0.008    0.001 reductions.py:75(free_dead_references)\n",
      "      938    0.003    0.000    8.978    0.010 dataloader.py:1266(_get_data)\n",
      "      938    0.003    0.000    8.653    0.009 connection.py:253(poll)\n",
      "     1876    0.002    0.000    0.009    0.000 reductions.py:299(storage_from_cache)\n",
      "      683    0.002    0.000    0.003    0.000 {method 'update' of 'set' objects}\n",
      "7656/7651    0.002    0.000    0.002    0.000 {built-in method builtins.len}\n",
      "      938    0.002    0.000    0.067    0.000 dataloader.py:1368(_process_data)\n",
      "      939    0.002    0.000    0.002    0.000 typing.py:271(inner)\n",
      "        7    0.002    0.000    0.002    0.000 {built-in method sys.getwindowsversion}\n",
      "     4710    0.002    0.000    0.002    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        8    0.002    0.000    0.033    0.004 {method 'dump' of '_pickle.Pickler' objects}\n",
      "     2064    0.001    0.000    0.003    0.000 reductions.py:34(expired)\n",
      "      939    0.001    0.000    0.031    0.000 _ops.py:286(__call__)\n",
      "      939    0.001    0.000    0.026    0.000 _ops.py:497(__call__)\n",
      "     1876    0.001    0.000    0.001    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "     1925    0.001    0.000    0.051    0.000 {built-in method builtins.next}\n",
      "      950    0.001    0.000    0.002    0.000 threading.py:256(__enter__)\n",
      "     2575    0.001    0.000    0.001    0.000 connection.py:134(_check_closed)\n",
      "     1884    0.001    0.000    0.001    0.000 {method '_weak_ref' of 'torch._C.StorageBase' objects}\n",
      "     1906    0.001    0.000    0.002    0.000 reductions.py:37(__del__)\n",
      "     1880    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "     4747    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      950    0.001    0.000    0.001    0.000 threading.py:259(__exit__)\n",
      "     1876    0.001    0.000    0.001    0.000 {method '_shared_decref' of 'torch._C.StorageBase' objects}\n",
      "     2064    0.001    0.000    0.001    0.000 storage.py:902(_expired)\n",
      "      950    0.001    0.000    0.001    0.000 threading.py:271(_is_owned)\n",
      "     1884    0.001    0.000    0.001    0.000 {built-in method __new__ of type object at 0x00007FFDDA34DC60}\n",
      "      946    0.001    0.000    0.049    0.000 dataloader.py:623(_next_index)\n",
      "     1876    0.001    0.000    0.001    0.000 {built-in method time.monotonic}\n",
      "     1876    0.001    0.000    0.001    0.000 connection.py:138(_check_readable)\n",
      "     1906    0.001    0.000    0.001    0.000 storage.py:766(_free_weak_ref)\n",
      "      699    0.001    0.000    0.001    0.000 connection.py:168(fileno)\n",
      "     1906    0.001    0.000    0.001    0.000 {built-in method _free_weak_ref}\n",
      "     2064    0.001    0.000    0.001    0.000 {built-in method _expired}\n",
      "      683    0.001    0.000    0.001    0.000 connection.py:903(<listcomp>)\n",
      "      950    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "      160    0.001    0.000    0.001    0.000 {method 'bit_length' of 'int' objects}\n",
      "     1359    0.001    0.000    0.001    0.000 connection.py:902(<genexpr>)\n",
      "       30    0.001    0.000    0.001    0.000 {built-in method _winapi.CloseHandle}\n",
      "      879    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "     1360    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      939    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "      577    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "     1876    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_winapi.Overlapped' objects}\n",
      "      939    0.000    0.000    0.000    0.000 _jit_internal.py:1102(is_scripting)\n",
      "      950    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      938    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "      695    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "      683    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _winapi.CreateNamedPipe}\n",
      "      941    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "       15    0.000    0.000    0.001    0.000 synchronize.py:50(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method nt.lstat}\n",
      "      160    0.000    0.000    0.001    0.000 random.py:237(_randbelow_with_getrandbits)\n",
      "      939    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "        4    0.000    0.000    0.173    0.043 threading.py:280(wait)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:225(__init__)\n",
      "        4    0.000    0.000    0.120    0.030 popen_spawn_win32.py:44(__init__)\n",
      "       16    0.000    0.000    0.001    0.000 reduction.py:106(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 reductions.py:151(reduce_tensor)\n",
      "      160    0.000    0.000    0.001    0.000 random.py:343(choice)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _winapi.OpenProcess}\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method _winapi.DuplicateHandle}\n",
      "        5    0.000    0.000    0.003    0.001 queues.py:37(__init__)\n",
      "        4    0.000    0.000    0.173    0.043 threading.py:563(wait)\n",
      "        8    0.000    0.000    0.030    0.004 reductions.py:353(reduce_storage)\n",
      "        4    0.000    0.000    0.174    0.044 queues.py:161(_start_thread)\n",
      "        5    0.000    0.000    0.002    0.000 connection.py:535(Pipe)\n",
      "       16    0.000    0.000    0.001    0.000 connection.py:956(reduce_pipe_connection)\n",
      "       36    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)\n",
      "        1    0.000    0.000    0.313    0.313 dataloader.py:994(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _winapi.CreatePipe}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       20    0.000    0.000    0.001    0.000 tempfile.py:149(__next__)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _winapi.CreateFile}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        8    0.000    0.000    0.033    0.004 reduction.py:58(dump)\n",
      "        9    0.000    0.000    0.000    0.000 threading.py:228(__init__)\n",
      "       20    0.000    0.000    0.001    0.000 tempfile.py:152(<listcomp>)\n",
      "        6    0.000    0.000    0.001    0.000 context.py:65(Lock)\n",
      "        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)\n",
      "        5    0.000    0.000    0.003    0.001 context.py:100(Queue)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _winapi.ConnectNamedPipe}\n",
      "        8    0.000    0.000    0.000    0.000 util.py:186(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 _tensor.py:237(_typed_storage)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        4    0.000    0.000    0.121    0.030 process.py:110(start)\n",
      "       15    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:80(__init__)\n",
      "       47    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:398(parent)\n",
      "      128    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:802(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 connection.py:158(readable)\n",
      "       14    0.000    0.000    0.736    0.053 popen_spawn_win32.py:101(wait)\n",
      "        4    0.000    0.000    0.120    0.030 context.py:324(_Popen)\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)\n",
      "       36    0.000    0.000    0.000    0.000 popen_spawn_win32.py:97(duplicate_for_child)\n",
      "        5    0.000    0.000    0.000    0.000 context.py:85(BoundedSemaphore)\n",
      "        5    0.000    0.000    0.001    0.000 tempfile.py:395(mktemp)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:568(__init__)\n",
      "       36    0.000    0.000    0.000    0.000 reduction.py:71(duplicate)\n",
      "        2    0.000    0.000    0.737    0.368 dataloader.py:1401(_shutdown_workers)\n",
      "       82    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        5    0.000    0.000    0.000    0.000 queues.py:71(_reset)\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       10    0.000    0.000    0.000    0.000 ntpath.py:124(splitdrive)\n",
      "        8    0.000    0.000    0.001    0.000 util.py:205(__call__)\n",
      "        1    0.000    0.000   10.267   10.267 2156649156.py:6(<module>)\n",
      "        5    0.000    0.000    0.001    0.000 connection.py:69(arbitrary_address)\n",
      "      264    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:78(get_command_line)\n",
      "    20/19    0.000    0.000    0.000    0.000 dataloader.py:419(__setattr__)\n",
      "        5    0.000    0.000    0.000    0.000 _tensor.py:904(__len__)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _winapi.SetNamedPipeHandleState}\n",
      "        4    0.000    0.000    0.000    0.000 subprocess.py:282(_args_from_interpreter_flags)\n",
      "        5    0.000    0.000    0.000    0.000 ntpath.py:77(join)\n",
      "       20    0.000    0.000    0.000    0.000 tempfile.py:138(rng)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'untyped_storage' of 'torch._C._TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 queues.py:153(cancel_join_thread)\n",
      "       47    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        4    0.000    0.000    0.174    0.043 threading.py:880(start)\n",
      "        1    0.000    0.000    0.188    0.188 dataloader.py:1087(_reset)\n",
      "        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)\n",
      "        8    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)\n",
      "       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "       48    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)\n",
      "        4    0.000    0.000    0.736    0.184 process.py:142(join)\n",
      "        8    0.000    0.000    0.000    0.000 storage.py:236(is_cuda)\n",
      "        4    0.000    0.000    0.000    0.000 module.py:1601(__getattr__)\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:61(_cleanup)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 tempfile.py:76(_exists)\n",
      "        4    0.000    0.000    0.000    0.000 ipkernel.py:768(init_closure)\n",
      "        6    0.000    0.000    0.001    0.000 synchronize.py:161(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "       39    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:204(_finalize_close)\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method _winapi.GetCurrentProcess}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000   10.267    5.134 interactiveshell.py:3514(run_code)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method msvcrt.open_osfhandle}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       10    0.000    0.000    0.000    0.000 popen_spawn_win32.py:117(poll)\n",
      "        4    0.000    0.000    0.120    0.030 context.py:222(_Popen)\n",
      "        1    0.000    0.000    0.000    0.000 2358583307.py:19(get_dataloader)\n",
      "        4    0.000    0.000    0.000    0.000 popen_spawn_win32.py:28(_close_handles)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:528(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 _namedtensor_internals.py:10(check_serializing_named_tensor)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1229(_make_invoke_excepthook)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:142(__call__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _winapi.GetExitCodeProcess}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:1375(_mark_worker_as_unavailable)\n",
      "       12    0.000    0.000    0.000    0.000 spawn.py:87(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 popen_spawn_win32.py:57(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.cpu_count}\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:327(is_set)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:39(_remove)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:489(check_worker_number_rationality)\n",
      "        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method nt.getcwd}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:144(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 mnist.py:152(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:140(close)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 context.py:90(Event)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:99(_get_distributed_settings)\n",
      "        8    0.000    0.000    0.000    0.000 {method '_shared_incref' of 'torch._C.StorageBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 hooks.py:82(warn_if_has_hooks)\n",
      "       32    0.000    0.000    0.000    0.000 connection.py:163(writable)\n",
      "        4    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)\n",
      "       10    0.000    0.000    0.000    0.000 context.py:233(get_context)\n",
      "       16    0.000    0.000    0.000    0.000 context.py:187(get_context)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1162(daemon)\n",
      "       23    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:95(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C._TensorBase' objects}\n",
      "       15    0.000    0.000    0.000    0.000 context.py:197(get_start_method)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:777(__reduce_ex__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:75(Condition)\n",
      "        1    0.000    0.000    0.313    0.313 dataloader.py:383(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:613(_reset)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        2    0.000    0.000   10.267    5.134 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:234(ident)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:114(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        8    0.000    0.000    0.000    0.000 reductions.py:343(reduce_typed_storage)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:673(is_initialized)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 2156649156.py:7(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 torch.py:244(train_dataloader)\n",
      "        4    0.000    0.000    0.000    0.000 subprocess.py:272(_optim_args_from_interpreter_flags)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:265(_release_save)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:261(helper)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:205(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:226(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 dataloader.py:1082(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1147(daemon)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method nt.fspath}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:62(get_sharing_strategy)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 tempfile.py:229(_get_candidate_names)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3466(compare)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)\n",
      "        8    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "        1    0.000    0.000    0.313    0.313 dataloader.py:429(__iter__)\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:536(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:393(WORLD)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:394(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1255(user_global_ns)\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:45(get_executable)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:213(authkey)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1478(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:313(default_pg)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:189(name)\n",
      "        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:276(_close)\n",
      "        3    0.000    0.000    0.000    0.000 dataloader.py:444(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1103(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1375(cast)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:448(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:390(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "# Call the function you want to profile\n",
    "load_time(data)\n",
    "profiler.disable()\n",
    "profiler.print_stats(sort=\"tottime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in method `_winapi.WaitForMultipleObjects` took the most time. ？？\n",
    "\n",
    "Ways to improve it: use multithread to load data in parallel, use efficient data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check out the framework’s online API documentation. Which other datasets are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Image classification:** Caltech 101 Dataset, Caltech 256 Dataset, Large-scale CelebFaces Attributes (CelebA) Dataset Dataset, CIFAR10 Dataset, CIFAR100 Dataset...\n",
    "- **Image detection or segmentation:** MS Coco Detection Dataset, Cityscapes Dataset, KITTI Dataset...\n",
    "- **Optical Flow**\n",
    "- **Stereo Matching**\n",
    "- ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
