{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given the final code example in this section with kernel size (3,5), padding (0,1), and stride (3,4), calculate the output shape to check if it is consistent with the experimental result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$out_x = (8 - 3 + 0 + 3) / 3 = 2$$\n",
    "$$out_y = (8 - 5 + 1 + 4) / 4 = 2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For audio signals, what does a stride of 2 correspond to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used to downsample the signal and extract high level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement mirror padding, i.e., padding where the border values are simply mirrored to extend tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Padded tensor:\n",
      "tensor([[[[9., 8., 7., 8., 9., 8., 7.],\n",
      "          [6., 5., 4., 5., 6., 5., 4.],\n",
      "          [3., 2., 1., 2., 3., 2., 1.],\n",
      "          [6., 5., 4., 5., 6., 5., 4.],\n",
      "          [9., 8., 7., 8., 9., 8., 7.],\n",
      "          [6., 5., 4., 5., 6., 5., 4.],\n",
      "          [3., 2., 1., 2., 3., 2., 1.]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator.DESKTOP-II8P465\\AppData\\Local\\Temp\\ipykernel_9556\\1423821385.py:9: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  X = torch.range(1,9).reshape(3 ,3)\n"
     ]
    }
   ],
   "source": [
    "def mirror_padding(X, padding_size):\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    padded_tensor = torch.nn.functional.pad(X,\n",
    "                                            (padding_size[1], padding_size[1], padding_size[0], padding_size[0]),\n",
    "                                            mode='reflect')\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "X = torch.range(1,9).reshape(3 ,3)\n",
    "padded_tensor = mirror_padding(X, (2,2))\n",
    "print(\"Original tensor:\")\n",
    "print(X)\n",
    "print(\"Padded tensor:\")\n",
    "print(padded_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What are the computational benefits of a stride larger than 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger strides result in fewer convolutional operations and reduces the spatial resolution of the output feature maps. It reduced the computational load and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What might be statistical benefits of a stride larger than 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A larger stride can lead to more statistically independent outputs. When the stride is large, the receptive fields of adjacent output units have less overlap, resulting in less correlated responses. This can be advantageous when you want to capture diverse and distinct features across different regions of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How would you implement a stride of $\\frac{1}{2}$? What does it correspond to? When would this be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([1, 3, 16, 16])\n",
      "Output tensor shape: torch.Size([1, 3, 31, 31])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 3, 16, 16)\n",
    "transposed_conv = nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=3, stride=2, padding=1)\n",
    "output_tensor = transposed_conv(input_tensor)\n",
    "\n",
    "# Print the shapes of input and output tensors\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "print(\"Output tensor shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can  “upsamples” the input tensor by creating larger output feature maps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
