{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from d2l import torch as d2l\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume that the inputs $\\mathbf{X}$ to some scalar function $f$ are $n \\times m$ matrices. What is the dimensionality of the gradient of $f$ with respect to $\\mathbf{X}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n \\times m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add a bias to the hidden layer of the model described in this section (you do not need to include bias in the regularization term).\n",
    "    1. Draw the corresponding computational graph.\n",
    "    2. Derive the forward and backward propagation equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "![5_3_1](5_3_1.png)\n",
    "\n",
    "(2)\n",
    "\n",
    "The foward propagation:\n",
    "\n",
    "$$\\mathbf{z}= \\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}$$\n",
    "$$\\mathbf{h}= \\phi (\\mathbf{z}).$$\n",
    "$$\\mathbf{o}= \\mathbf{W}^{(2)} \\mathbf{h} + \\mathbf{b}^{(2)}$$\n",
    "$$L = l(\\mathbf{o}, y).$$\n",
    "$$J = L + s.$$\n",
    "\n",
    "The backward propagation:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial L} = 1 \\; \\textrm{and} \\; \\frac{\\partial J}{\\partial s} = 1.$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{o}}\n",
    "= \\textrm{prod}\\left(\\frac{\\partial J}{\\partial L}, \\frac{\\partial L}{\\partial \\mathbf{o}}\\right)\n",
    "= \\frac{\\partial L}{\\partial \\mathbf{o}}\n",
    "\\in \\mathbb{R}^q.$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{b}^{(2)}}= \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{b}^{(2)}}\\right) = \\frac{\\partial L}{\\partial \\mathbf{o}}\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial s}{\\partial \\mathbf{W}^{(1)}} = \\lambda \\mathbf{W}^{(1)}\n",
    "\\; \\textrm{and} \\;\n",
    "\\frac{\\partial s}{\\partial \\mathbf{W}^{(2)}} = \\lambda \\mathbf{W}^{(2)}.$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{W}^{(2)}}= \\frac{\\partial J}{\\partial \\mathbf{o}} \\mathbf{h}^\\top + \\lambda \\mathbf{W}^{(2)}.$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mathbf{h}}\n",
    "= \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{h}}\\right)\n",
    "= {\\mathbf{W}^{(2)}}^\\top \\frac{\\partial J}{\\partial \\mathbf{o}}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mathbf{z}}\n",
    "= \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{h}}, \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z}}\\right)\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{h}} \\odot \\phi'\\left(\\mathbf{z}\\right).\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{b}^{(1)}}=\\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{z}}, \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{b}^{(1)}}\\right)\n",
    "=\\frac{\\partial J}{\\partial \\mathbf{h}} \\odot \\phi'\\left(\\mathbf{z}\\right)$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}^{(1)}}\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{z}} \\mathbf{x}^\\top + \\lambda \\mathbf{W}^{(1)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the memory footprint for training and prediction in the model described in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               aten::mm         3.37%     542.647ms         3.37%     542.681ms     769.760us     240.81 Mb     240.81 Mb           705  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        70.90%       11.429s        70.96%       11.439s      41.295ms     209.92 Mb     209.46 Mb           277  \n",
      "                                            aten::addmm         7.26%        1.170s        13.90%        2.240s       4.073ms      71.03 Mb      71.03 Mb           550  \n",
      "                                        aten::clamp_min         1.46%     235.710ms         1.46%     235.710ms     857.127us      68.36 Mb      68.36 Mb           275  \n",
      "                               aten::threshold_backward         1.32%     212.448ms         1.32%     212.448ms     904.034us      58.59 Mb      58.59 Mb           235  \n",
      "                                     aten::_log_softmax         0.57%      92.034ms         0.57%      92.034ms     334.669us       2.67 Mb       2.67 Mb           275  \n",
      "                                aten::nll_loss_backward         0.09%      14.217ms         0.09%      14.309ms      60.889us       2.29 Mb       2.29 Mb           235  \n",
      "                       aten::_log_softmax_backward_data         0.19%      31.006ms         0.19%      31.006ms     131.940us       2.29 Mb       2.29 Mb           235  \n",
      "                                            aten::empty         0.02%       2.518ms         0.02%       2.518ms       4.441us       1.69 Mb       1.69 Mb           567  \n",
      "                                              aten::sum         0.40%      64.555ms         0.41%      66.004ms     140.434us     244.18 Kb     244.18 Kb           470  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.120s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MLP(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens, lr, plot_flag=True):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(nn.Flatten(), nn.LazyLinear(num_hiddens),\n",
    "                                 nn.ReLU(), nn.LazyLinear(num_outputs))\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        if self.plot_flag:\n",
    "            self.plot('loss', l, train=True)\n",
    "        return l\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        Y_hat = self(*batch[:-1])\n",
    "        l = self.loss(Y_hat, batch[-1])\n",
    "        if self.plot_flag:\n",
    "            self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n",
    "            self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)\n",
    "        return l\n",
    "\n",
    "model = MLP(num_outputs=10, num_hiddens=256, lr=0.1, plot_flag=False)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=1)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_train\"):\n",
    "        trainer.fit(model, data)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "     aten::empty_strided         0.06%     205.000us         0.06%     205.000us     205.000us     179.44 Mb     179.44 Mb             1  \n",
      "             aten::addmm        58.41%     215.092ms        61.38%     226.026ms     113.013ms      60.88 Mb      60.88 Mb             2  \n",
      "         aten::clamp_min         3.84%      14.144ms         3.84%      14.144ms      14.144ms      58.59 Mb      58.59 Mb             1  \n",
      "                aten::to         3.54%      13.041ms        26.03%      95.854ms      95.854ms     179.44 Mb           0 b             1  \n",
      "          aten::_to_copy         0.03%      99.000us        22.49%      82.813ms      82.813ms     179.44 Mb           0 b             1  \n",
      "             aten::copy_        25.37%      93.430ms        25.37%      93.430ms      31.143ms           0 b           0 b             3  \n",
      "           aten::flatten         0.01%      19.000us         0.01%      33.000us      33.000us           0 b           0 b             1  \n",
      "    aten::_reshape_alias         0.00%      14.000us         0.00%      14.000us      14.000us           0 b           0 b             1  \n",
      "            aten::linear         0.01%      25.000us        61.41%     226.126ms     113.063ms      60.88 Mb           0 b             2  \n",
      "                 aten::t         0.01%      49.000us         0.02%      75.000us      37.500us           0 b           0 b             2  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 368.243ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_infer\"):\n",
    "        model(data.train.data.type(torch.float32))\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Assume that you want to compute second derivatives. What happens to the computational graph? How long do you expect the calculation to take?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational graph becomes deeper and more complex as it needs to capture not only the relationships between the parameters and the loss but also the relationships between the gradients and their gradients. \n",
    "\n",
    "Suppose we have N parameters in a network and the loss is a scalar. The first derivative has N elements. But the second derivative has N^2 elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Assume that the computational graph is too large for your GPU.\n",
    "    1. Can you partition it over more than one GPU?\n",
    "    2. What are the advantages and disadvantages over training on a smaller minibatch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) We can split the model or the minibatches on multiple GPUs.\n",
    "\n",
    "(2)Advantages :\n",
    "\n",
    "It allows us to work with larger models or datasets that wouldn’t fit in a single GPU’s memory.It can lead to faster training times due to parallel computation.\n",
    "\n",
    "Disadvantages :\n",
    "\n",
    "There’s a communication overhead when exchanging information between GPUs, which can slow down training. Synchronizing multiple GPUs can be complex, especially when dealing with asynchronous updates. Smaller minibatches can lead to more noisy gradient estimates, slowing down convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
