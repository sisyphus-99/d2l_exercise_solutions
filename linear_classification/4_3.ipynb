{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Denote by $L_v$ the validation loss, and let $L_v^q$ be its quick and dirty estimate computed by the loss function averaging in this section. Lastly, denote by $l_v^b$ the loss on the last minibatch. Express $L_v$ in terms of $L_v^q$, $l_v^b$, and the sample and minibatch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suppose there are N examples and the batchsize is B. Since N may not divisible by B, the last batch may contain less than B examples:\n",
    "\n",
    "$$N = M B + b, B - b = c$$\n",
    "\n",
    "We suppose there are M batches each of which contains B examples, and the last batch contain b examples.\n",
    "\n",
    "So the quick esimate is:\n",
    "\n",
    "$$L_v^q = \\frac{\\sum_{i=1}^M (l_v^i) + l_v^b}{M + 1}$$\n",
    "\n",
    "The actual average loss is:\n",
    "\n",
    "$$L_v = \\frac{\\sum_{i=1}^M (B * l_v^i) + b * l_v^b}{N}= \\frac{B \\sum_{i=1}^M (l_v^i) + b * l_v^b}{MB + b}$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$L_v = L_v^q (1 + \\frac{c}{N}) - l_v^b \\frac{c}{N}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Show that the quick and dirty estimate $L_v^q$ is unbiased. That is, show that $E[L_v]=E[L_v^q]$. Why would you still want to use $L_v$ instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, c is smaller than batchsize b. Generally, the batchsize b is much smaller than N. So $\\frac{c}{N}$ is close to zero.\n",
    "\n",
    "$$E(L_v) = E(L^q_v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Given a multiclass classification loss, denoting by $l(y,y')$ the penalty of estimating $y$ when we see $y$ and given a probabilty $p(y|x)$, formulate the rule for an optimal selection of $y'$. Hint: express the expected loss, using $l$ and $p(y|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(l) = \\sum p(y | x) l(y,y')$$\n",
    "\n",
    "$$y_{opt}'=\\arg \\min_{y'} (E(l))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
